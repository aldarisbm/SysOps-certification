## S3 Overview

- Globally Unique
- Regionally provisioned

- Key is fullpath
    - s3://mybucket/[my_file.txt] -> Key
    - s3://mybucket/[hello/world.txt] -> Key

- Key is composed by key prefix + object name
    - prefix /hello
    - object name world.txt

- There's no concept of directories within buckets
    - UI "tricks" you otherwise

- Object Values are the content of the body
    - Max is 5TB
    - Cannot more than 5GB at a time (multi-part upload)

- Metadata (list of text key/value pais - system or user metadata)
- Tags (unicode k/v up to 10)
- Version ID (if versioning is enabled)

- s3 bucket view shows buckets in all regions
- If you right click -> open an s3 object it uses presigned urls

### Versioning
- Has to be enabled at the bucket level
- Same key overwrite will increment the version -> 1 -> 2 -> 3 (intricate string)
- It is best practice to version your buckets
    - Protect against unintended deletes (ability to restore a version)
    - any file that is not versioned prior to enabling versioning will have version `null`
- If you delete an object you get a:
    - delete marker
    - if you delete the `delete marker` it shows again
    - you can delete specific versions

### Encryption
- SSE-S3 - keys handled n managed by AWS
- SSE-KMS - KMS to manage encryption keys
- SSE-C - When you want to manage your own encryption keys
- Client Side Encryption

- SSE-S3
    - Keys handled n managed by AWS s3
    - Object is encrypted server side
    - must set header

- KMS
    - Keys handled n managed by KMS
    - user control + audit trail
    - Object is encrypted server side
    - must set header

- SSE-C
    - S3 does not store the encryption key you provide
    - HTTPS must be used!! (youre sending the key)
    - Encryption key must ve provided in HTTP headers, for every HTTP req made
    - AMazon does not keep the key

- Client Side Encryption
    - Clients library such as the Amazon S3 encrpytion client
    - Clients must encrypt n decrypt the data themselves before sending and after retrieving from s3
    - Client fully manages the key and encryption cycle

- Encryption in flight is also called SSL/TLS

- Default Encrpytion
    - AES-256
    - KMS
    - NONE

### S3 Security
- User based
    - IAM policies (which API calls they are allowe to make)
- Resource based
    - Bucket Policies - bucket wide rules from the s3 console - allows cross acct
- Object ACL
    - finer grain
- Bucket ACL
    - less common

- an IAM principal can access an s3 object if
    - the user IAM policies allow it OR the resource policy allows it
    - AND theres no explicit DENY

- S3 Bucket policy
    - JSON based
    - Resources:
        - Buckets
        - Object
    - Effect
        - Allow
        - Deny
    - Principal
        - Acct or user
    - grant public access to the bucket
    - grant access to another acct
    - force objects to be encrypted on upload

### Bucket settings for Block Public Access
- Block public acces to buckets n objects granted through
    - new acces control lists
    - any access control list
    - new public bucket or access point policies
- Block public and cross-acount access to bucket and objects through any public bucket or access point policies

- S3 Security - Other
    - Supports VPC endpoints (for instances in VPC without interwebs)
    - Loggin and Audit
        - S3 acces logs can be stored in other s3 buck
        - API calls can be logged in AWS cloudtrail
    - User Security
        - MFA DELETE
        - Pre-Signed URLs


### CORS
- Same origin www.example.com/hello && www.example.com/world
- Diff origin api.example.com/hello && www.example.com/world

### S3 Consistency Model
- Eventually consistent
- Read after write consistency for PUTS of new objects
    - PUT 200 -> GET 200
    - GET 404 -> PUT 200 -> GET 404 (eventually consistent) 
- Eventual consistency
    - If you read an object right after updating it, you might get the older version 
        - PUT 200 -> PUT 200 -> GET 200 (might be older version)
        - DELETE 200 -> GET 200! (you might have a successful get - Eventual consistency)
- No way to get strong consistency

### S3 For SysOps

#### Versioning
- S3 vers creates a new version each time you change a file
- that includes when you encrypt a file!
- Its a nice way to get protected against hackers wanting to encrypt our data
- Delete a file in s3 just adds a delete marker
- To delete a bucket you need to delete all of the versions

#### MFA Delete
- NEED FOR:
    - Permanently delete an object version
    - suspend versioning on the bucket
- DONT NEED FOR:
    - enable versioning
    - list deleted versions
- Only the bucket owner (root account) can enable/disable MFA-DELETE
- MFA-Delete currently can only be enabled using the CLI
    - Only enabled with root acct creds
    - Once enabled you can only delete objects (versions) through the CLI with MFA

#### S3 Access logs

- For audit purposes
- Any request made to s3 from any acct auth or denied
- that data can be analyzed using data analytics tools

- Never set your logging bucket to the monitored bucket

#### S3 Replication (CRR & SRR)

- Must enable versioning
- Cross Region Replicatoin
- Same Region Replication
- Buckets in diff accts
- Copying is async
- Must give proper IAM permissions to S3

- CRR uses cases:
    - Compliance
    - Lower latency
    - Repl acc accounts
- SRR use cases
    - Log aggre
    - Live repli between prod and test
- Not retroactive
    - only new objects get replicated
- Delete Operations
    - Not replicated!!
- There's no "chaining" of replication

#### S3 pre-signed URLs

- Can generate pre-signed URLs using SDK or CLI
    - For downloads (CLI)
    - For uploads (SDK)

- Valid for default 3600seconds (1hr) `--expires-in` seconds arg
- Users given a pre-signed URL inherit permissions of the person who generated the URL for GET/PUT

- Examples:
    - Allow only logged-in users to download a premium video on your S3 bucket
    - Allow an ever chaning list of users to download files by generating URLs dynamically
    - Allow temporarily a user to upload a file to a precise location in our bucket

### CloudFront

- Content Delivery Network (CDN)
- Improves read performance (cached at edge)
- 216 points of presence globally (edge locations)

- DDoS protection, integration with Shield, AWS Web App Firewall (wAF
- Can expose external HTTPS and can talk to internal HTTPS backends

#### CloudFront Origins

- S3 Bucket
    - For distrb files and caching them at the edge
    - enhanced security with cloudfront (OAI)
    - CloudFront can be used as an ingress (uploda to s3)
- Custom Origin(HTTP)
    - ALB
    - EC2
    - S3 Website (must enable bucket as static s3 webs)
    - Any HTTP backend you want

#### CloudFront Geo Restriction
- You can restrict who can access
    - Whitelist
    - Blacklist

- The "country" is determined using a 3rd party Geo-IP database
- Use case: Copyrights law to control access to your content

#### CloudFront vs S3 Cros Region Replication
- CloudFront:
    - Global Edge Network
    - Files are cached for a TTL (maybe a day)
    - Great for static content that muts be available everywhere

- S3 CRR:
    - Must be setup for reach region you want repl to happen
    - files are updated in near real time
    - read only
    - great fot dynamic content that needs to be avail at low-latency in a few regions

#### CloudFront Access Logs
- All edge locations access log can go to one log bucket

#### CloudFront Reports
- Possible to generate on
    - caches statistics
    - popular objects
    - top referrers
    - usage
    - viewers
- Based on the access logs data

- Cloufront troubleshooting
    - CloudFront caches HTTP 4xx and 5xx status codes returned by s3

- 4xx error code indicates that user doesnt have access to the underlying bucket (403) or the object is requesting is not found
- 5xx error odes indicates gateway issues

### S3 Inventory
- Amazon s3 inventory helps manage your storage
- Audit and report on the replication and encryption status of your objects
- Use cases
    - business
    - compliance
    - reg needs

- You can query w athena, redshift, presto, hive, spark

- YOu can setup multiple inventories
- data goes from a source bucket to a target bucket (need to setup policy)




